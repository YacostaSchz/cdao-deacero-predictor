# Opciones de Arquitectura en GCP para Desplegar el Modelo de Predicción de Precios

## Contexto y Requisitos Clave

Para desplegar un **API REST predictivo** que proporcione el precio de cierre del día siguiente de la varilla corrugada (acero), se debe diseñar una arquitectura en **Google Cloud Platform (GCP)** que cumpla con las restricciones técnicas y de negocio. Los requisitos principales a considerar son:

·  	**Presupuesto cloud muy limitado**: La solución debe operar con menos de **$5 USD/mes**\[1\], aprovechando al máximo las capas gratuitas de GCP.

·  	**Rendimiento del endpoint**: Debe exponer un único endpoint (GET /predict/steel-rebar-price) con respuesta \< **2 segundos**\[1\] incluso a picos de **60 solicitudes por minuto** (≈1 req/s). Se espera \~7,200 solicitudes en 5 días de evaluación.

·  	**Autenticación y cuota**: El endpoint requiere autenticación mediante API Key (header X-API-Key) y **rate limiting** de \~100 requests/hora por key (según lo indicado en el documento técnico). Idealmente, la arquitectura debería soportar estas restricciones sin comprometer costo.

·  	**Retraining del modelo**: El modelo se entrenará inicialmente de forma local, pero las re-entrenamientos periódicos deberán realizarse en la nube. Los **datos son de frecuencia mensual** principalmente (volatilidad diaria baja, hipotéticamente), por lo que actualizaciones del modelo podrían ser mensuales en lugar de diarias.

·  	**Cálculo previo de predicciones**: Dado que los datos nuevos aparecen con poca frecuencia, **se puede precalcular la predicción** (por ejemplo, una vez al día) en lugar de computarla en cada solicitud. Esto reduce la carga en tiempo real y asegura respuestas rápidas y consistentes (se menciona cache de hasta 1 hora para evitar recálculos innecesarios\[2\]).

·  	**Tecnologías permitidas**: Se pueden usar lenguajes como Python, Node.js, etc. y servicios GCP diversos (Vertex AI, BigQuery, Cloud Functions, Cloud Run, etc.). No se pueden usar APIs de terceros que sean de pago o requieran licencias\[1\].

A continuación se presentan **tres opciones de arquitectura** en GCP que podrían satisfacer estos requerimientos, junto con sus componentes, ventajas, desafíos y estimación de dificultad de implementación.

## Opción 1: Cloud Run con Modelo Pre-entrenado y Predicción Precalculada

**Descripción**: Desplegar el modelo dentro de un servicio **Cloud Run** (entorno serverless con contenedores). El modelo se entrena offline o en la nube, y sus predicciones (por ejemplo, el precio para el día siguiente) se calculan periódicamente y se almacenan para ser servidas rápidamente por el endpoint. Cloud Run alojará una aplicación (por ejemplo, API REST con Flask/FastAPI en Python) que entrega la predicción en formato JSON.

·  	**Componentes**:

·  	Un contenedor Docker con la aplicación web y el modelo ML (o lógica para obtener la predicción precalculada).

·  	**Cloud Run Service** desplegado desde ese contenedor, que maneja las solicitudes HTTP (GET /predict/steel-rebar-price).

·  	Un mecanismo de **schedule/cache**: Por ejemplo, un **Cloud Scheduler** diario que desencadene una tarea (Cloud Run Job o Cloud Function) para recalcular la predicción del día siguiente y guardarla (en memoria, en **Cloud Storage** como archivo JSON, o en una base ligera como **Firestore**). La aplicación Cloud Run leerá esta predicción almacenada en cada request en lugar de recalcular en vivo.

* Implementación de **auth y rate-limiting** en la aplicación: verificar el X-API-Key entrante y, opcionalmente, mantener conteo de llamadas por hora (posiblemente almacenando contadores en Firestore o en memoria si solo hay una instancia). Alternativamente, usar **API Gateway** de GCP al frente para manejar API Keys y cuotas, aunque podría agregar costo (API Gateway se cobra por llamada, aunque a baja tasa).  
* **Ventajas**:  
  ·  	**Costo bajo**: Cloud Run es **serverless** y escala a cero instancias cuando no hay tráfico, evitando costos fijos. GCP ofrece una capa gratuita generosa para Cloud Run: *180,000 segundos de vCPU, 360,000 segundos-GiB de memoria, y 2 millones de solicitudes al mes sin coste*[\[3\]](https://www.reddit.com/r/googlecloud/comments/ow15n0/cloud_run_free_tier/#:~:text=The%20free%20tier%20specifically%20is%3A)[\[4\]](https://cloudchipr.com/blog/google-cloud-functions#:~:text=Free%20tier%20recap%20,central1%20example). Esto probablemente cubra nuestras \~7k solicitudes de evaluación, manteniendo el costo prácticamente en $0.  
  ·  	**Desempeño**: Cloud Run puede manejar 60 req/min fácilmente con una instancia pequeña, y al precalcular la respuesta, el tiempo de inferencia es mínimo (básicamente una lectura de valor precalculado). La respuesta estará muy por debajo de 2s.  
  ·  	**Flexibilidad**: Podemos usar cualquier lenguaje o framework. Incluir librerías de ML, lógica de cache, etc., sin restricciones. A diferencia de Vertex Endpoints, Cloud Run no impone requisitos estrictos en la imagen de contenedor y **permite cargas personalizadas**[\[5\]](https://datatonic.com/insights/deploying-machine-learning-models-google-cloud/#:~:text=Deploying%20models%20with%20Google%20Cloud,no%20restrictions%20on%20container%20images). También soporta concurrencia (varias solicitudes por instancia) para eficiencia.  
  ·  	**Escalabilidad**: Escala automáticamente si aumenta la carga (hasta el límite deseado), manteniendo baja la latencia. Como es serverless, no hay que gestionar servidores.  
* **Sin costo en inactividad**: A diferencia de un endpoint de Vertex AI, Cloud Run **puede escalar a cero** cuando no se usa[\[6\]](https://datatonic.com/insights/deploying-machine-learning-models-google-cloud/#:~:text=and%20poses%20no%20restrictions%20on,container%20images), evitando cargos cuando no hay peticiones. Esto es crucial para mantenernos bajo $5/mes.  
* **Desafíos**:  
  ·  	**Dificultad de implementación**: *Moderada*. Se requiere crear un Dockerfile y manejar el despliegue. También implementar manualmente detalles como la autenticación por API Key y el almacenamiento/cache de la predicción. La lógica de **rate limiting** por API key podría complicarse sin un almacenamiento centralizado; implementarla estrictamente puede requerir usar algún servicio (p. ej., Redis/Memorystore o Firestore) para contar peticiones por hora, lo que aumenta complejidad. Sin embargo, dado el bajo volumen esperado, quizás se pueda simplificar (p.ej., asumir que los evaluadores no excederán 100/hora por key).  
  ·  	**Mantenimiento de estado/cache**: Las instancias de Cloud Run son efímeras; si usamos caché en memoria, cada instancia tendría su propio valor. Para garantizar una respuesta consistente, la opción más simple es almacenar la predicción en **Cloud Storage o Firestore** compartido. Esto agrega ligera latencia (milisegundos) al leer, pero todavía dentro de límites aceptables, o se puede cargar en memoria al iniciar la instancia y actualizar cada hora.  
  ·  	**Startup (cold start)**: Cloud Run puede demorar un par de segundos en iniciar una instancia si estuvo escalado a cero. No obstante, con tráfico regular (60 req/min) mantendrá caliente la instancia. Además, la capa gratis cubre CPU durante arranque también. Aún en cold start, cumpliría el SLA de \<2s si la lógica es simple.  
* **Herramientas adicionales**: Se debe configurar Cloud Scheduler si se usa para la tarea diaria de retraining/predicción. Esto es sencillo, pero es un componente más a manejar (aunque su costo es despreciable, \<$0.10 por millón de ejecuciones).  
* **Consideraciones de implementación**: En esta opción, la **predicción precalculada** podría generarse mediante una función que obtenga los datos más recientes (por ejemplo, últimos precios de commodity de una API pública o BigQuery), ejecute el modelo para el siguiente día, y escriba el resultado en JSON. Esa función puede ejecutarse cada noche. El endpoint al ser llamado solo devuelve ese JSON (junto con metadata como fecha de predicción, confianza, etc. según formato requerido\[7\]). Esto cumple con el requisito de cachear hasta por 1 hora las predicciones\[2\] y evita recálculo por cada solicitud.

En resumen, **Cloud Run** ofrece una solución robusta, de bajo costo y relativamente fácil de escalar. Es probablemente la opción más balanceada para este caso, dado el presupuesto y las necesidades. Google Cloud incluso la destaca como servicio recomendado para desplegar modelos ML en contenedores por su flexibilidad y eficiencia[\[8\]](https://niveussolutions.com/google-cloud-ai-models-deployment/#:~:text=Relevant%20Google%20Cloud%20Services%20for,Model%20Deployment). La implementación requiere conocimientos de Docker y algo de código para orquestar la cache y los endpoints, pero muchos [ejemplos y guías](https://cloud.google.com/run/docs/quickstarts) están disponibles, lo que disminuye la dificultad.

**Dificultad estimada**: **Media.** Montar un servicio en Cloud Run con Docker y FastAPI/Flask es razonablemente directo para un desarrollador familiar con Python. Manejar el cron job de predicción y el almacenamiento de cache añade algo de complejidad, pero sigue siendo manejable. En cuanto a esfuerzos: implementar autenticación por API Key es trivial; implementar rate limiting estricto es más complejo, pero dado el bajo tráfico esperado, se podría omitir o hacer de forma simplificada. En general, es una opción viable en el plazo corto (7 días) de la prueba técnica, aprovechando muchas capacidades serverless de GCP sin salirse del presupuesto.

## Opción 2: Cloud Functions \+ BigQuery (Arquitectura 100% Serverless)

**Descripción**: Utilizar **Cloud Functions** (ahora integradas como Cloud Run functions 2nd gen) para el endpoint y **BigQuery** como plataforma de datos y modelado. En esta arquitectura, BigQuery puede usarse tanto para almacenar los datos históricos de precios como para entrenar un modelo de pronóstico usando **BigQuery ML**. La predicción se puede obtener mediante una consulta SQL (por ejemplo, usando ML.PREDICT de BigQuery ML sobre el modelo entrenado) y luego entregarla a través de una Cloud Function HTTP.

·  	**Componentes**:

·  	**BigQuery**: dataset con los datos históricos (por ejemplo, precios mensuales de la varilla corrugada, indicadores económicos correlacionados, etc.). BigQuery ML podría entrenar un modelo de serie de tiempo (p.ej. modelo ARIMA o regresión) directamente en SQL. Se aprovecharía la capa gratuita de BigQuery: hasta *1 TB de procesamiento de consultas y 10 GB de almacenamiento activos por mes sin costo*[\[9\]](https://www.getgalaxy.io/learn/glossary/is-bigquery-free#:~:text=Is%20BigQuery%20free%3F), suficiente para un dataset histórico modesto.

·  	**Cloud Functions (2da gen)**: Una función HTTP (en Python, Node u otro lenguaje permitido) que actúa como el endpoint /predict/steel-rebar-price. Esta función, al ser invocada, consulta la predicción en BigQuery **o** en un almacenamiento previamente actualizado.

`o`   En un esquema, la función podría ejecutar una query a BigQuery para obtener la predicción del día siguiente (ya sea calculándola en el momento con ML.FORECAST/ML.PREDICT, o leyendo de una tabla de “predicciones” precalculadas).

`o`   Alternativamente, para evitar latencia en cada request, se puede precalcular por adelantado: por ejemplo, usar Cloud Scheduler diario que dispare una función o procedimiento de BigQuery que almacene la predicción en una tabla. La Cloud Function simplemente leería el valor almacenado más reciente.

·  	**Almacenamiento de predicción**: Si no se quiere consultar BQ en cada request (por costo o tiempo), se puede usar **Firestore**, **Memorystore** o incluso **BigQuery** mismo (una pequeña tabla) para guardar la predicción del siguiente día, actualizada cada vez que se re-entrena o cada día. Firestore tiene cuota gratis (hasta 20k lecturas/día), ideal para leer un documento con la predicción. También una **Cloud Storage** JSON sería viable. La función lee este almacenamiento y construye la respuesta JSON para el cliente.

* **Auth & Rate limiting**: Similar a la opción 1, la Cloud Function debe validar la API Key en el header. Las funciones por defecto no traen un sistema de cuotas por usuario, así que habría que implementarlo manualmente (por ejemplo, usando Firestore para incrementar un contador por API Key y timestamp). Otra opción es configurar **API Gateway** delante de la Cloud Function para que aplique autentificación por API Key y límites de cuota automáticamente. API Gateway en GCP soporta definir un API Key y cuotas por cliente; sin embargo, hay un costo por solicitud (aunque bajo, del orden de $3 por millón de llamadas). Dado que solo serían \~7k llamadas en 5 días, el costo sería \<$0.02, por lo que es factible incorporar API Gateway sin romper el presupuesto, si se desea una solución más robusta.  
* **Ventajas**:  
  ·  	**Implementación sencilla del endpoint**: Cloud Functions permite desplegar código sin manejar infraestructura ni contenedores. Simplemente se escribe la función para manejar la petición HTTP. Esto puede ser más rápido de desarrollar si el candidato no está tan cómodo con Docker/Cloud Run. Además, el escalado, concurrencia y demás son gestionados automáticamente (basado en Cloud Run bajo el capó).  
  ·  	**Costos muy bajos**: Cloud Functions 2da gen tiene la *misma capa gratuita que Cloud Run* (comparten límites)[\[10\]](https://cloudchipr.com/blog/google-cloud-functions#:~:text=There%E2%80%99s%20also%20a%20free%20tier%3A,are%20billed%20separately)[\[4\]](https://cloudchipr.com/blog/google-cloud-functions#:~:text=Free%20tier%20recap%20,central1%20example). 2 millones de invocaciones/mes gratis cubren de sobra nuestro caso. BigQuery ofrece 1 TB/mes de consultas gratis; una consulta diaria o unas pocas consultas ligeras difícilmente excederán eso (los datos de precios son pequeños). El almacenamiento de 10 GB gratis también basta (los históricos de precios e indicadores ocupan quizás unos pocos MB). En resumen, esta arquitectura puede operar **prácticamente gratis** dentro de los límites siempre free de GCP[\[9\]](https://www.getgalaxy.io/learn/glossary/is-bigquery-free#:~:text=Is%20BigQuery%20free%3F)[\[4\]](https://cloudchipr.com/blog/google-cloud-functions#:~:text=Free%20tier%20recap%20,central1%20example).  
  ·  	**BigQuery ML**: Permite entrenar modelos de pronóstico de manera declarativa (SQL), lo que simplifica el pipeline de ML. Por ejemplo, se podría usar CREATE MODEL con MODEL\_TYPE="ARIMA\_PLUS" o una regresión, sin tener que desarrollar un pipeline de ML complejo. BigQuery ML entrenará el modelo en segundos/minutos dado el tamaño pequeño del dataset, y luego se puede obtener la predicción futura con una simple query. Esto evita tener que hospedar manualmente un modelo en código Python dentro del endpoint.  
  ·  	**Mantenimiento de datos centralizado**: Al tener los datos en BigQuery, es fácil actualizar el dataset con nuevos datos mensuales (se puede automatizar la ingesta con una función o carga manual). Además, se puede aprovechar SQL para agregar nuevas variables (indicadores macroeconómicos, etc. como sugieren en el caso técnico) de forma sencilla con JOINs.  
* **Escalabilidad**: BigQuery puede manejar más datos o consultas concurrentes sin cambios arquitectónicos. Cloud Functions escala automáticamente creando más instancias si llegan más de una petición simultánea (aunque en nuestro caso 1 req/s es manejado por una sola instancia fácilmente).  
* **Desafíos**:  
  ·  	**Latencia de BigQuery**: Ejecutar una consulta a BigQuery en tiempo real para cada request podría añadir latencia (BigQuery suele tardar cientos de milisegundos a \~1s en consultas pequeñas). Si bien podría aún quedar cerca de \~1s, es un factor a controlar. Para garantizar \<2s, sería mejor *no* hacer una consulta pesada en cada invocación. Solución: limitarse a leer una tabla con la predicción (lectura de una fila es muy rápida) o usar un cache en memoria. Otra opción es utilizar **BigQuery pequeño** (in-memory) como Firestore para lectura instantánea.  
  ·  	**Complejidad de BigQuery ML**: Aunque es poderoso, BigQuery ML soporta ciertos tipos de modelo (ARIMA, regresiones, XGBoost, redes neuronales básicas). Si el modelo óptimo es muy especializado (por ejemplo, una red neuronal LSTM), implementarlo en BQ ML sería imposible. En tal caso, habría que entrenar fuera (Python) y luego quizás almacenar los resultados en BigQuery. Sin embargo, dada la naturaleza del problema (predicción de serie de tiempo con patrones estacionales y tendencias), un ARIMA+ exógeno o regresión con variables económicas probablemente sea suficiente y BigQuery ML podría manejarlo.  
  ·  	**Stateful caching en Cloud Functions**: Las funciones son puramente stateless en cada invocación. No podemos conservar variables globales fácilmente entre invocaciones a menos que la misma instancia atienda varias (en 2da gen, una instancia puede reutilizarse, pero no garantizado). No obstante, al 1 req/s, es probable que haya reuso de instancias. Podríamos implementar un *simple cache en memoria dentro de la función* para no reconsultar BigQuery más de 1 vez por hora. Eso sí, si GCP escala otra instancia, esa no tendrá el valor cacheado. Por eso un almacenamiento externo (Firestore/Storage) es más confiable para compartir el cache.  
* **Rate limiting manual**: Igual que antes, limitar 100 req/h por key en Cloud Functions sin un middleware requiere persistir contadores entre invocaciones. Se puede usar Firestore TTL (cada llamada incrementa un doc con timestamp y se calculan cuántas en la última hora). Esta lógica lleva tiempo de implementar y probar. Alternativamente, delegar a API Gateway esa función simplifica la implementación (API Gateway permite configurar cuotas por clave). Dado el tiempo limitado de desarrollo (7 días), podría optarse por la solución manual más simple posible o documentar la intención sin implementar completamente.  
* **Dificultad estimada**: **Baja a Media.** Configurar BigQuery y escribir consultas ML es relativamente sencillo si se tiene experiencia básica con SQL. La Cloud Function en sí es trivial de escribir (unos pocos líneas para conectarse a BQ o Firestore y formatear la respuesta JSON). No se lidia con Docker ni con infraestructura de servidor. El principal reto radica en orquestar los componentes: programar actualizaciones del modelo (posiblemente usando Cloud Scheduler para lanzar un entrenamiento mensual en BigQuery ML), y manejar la autenticación/limites. Usar BigQuery ML también implica aprender su sintaxis y limitaciones, pero para este caso de uso no es complejo.

En general, esta opción ofrece **rapidez de desarrollo** y cero mantenimiento de servidores, a costa de delegar todo a servicios administrados (lo cual encaja con el presupuesto). Es ideal si se quiere minimizar código y aprovechar servicios GCP administrados al máximo. Un riesgo es que el candidato demuestre menos de sus habilidades de ingeniería de datos si delega demasiado en BigQuery ML; sin embargo, la opción es técnicamente válida y eficiente dentro de los lineamientos.

## Opción 3: Vertex AI (Entrenamiento Gestionado y Despliegue ML)

**Descripción**: Utilizar **Vertex AI** como plataforma integral para el ciclo de vida del modelo. Esto incluye entrenar el modelo en Vertex AI y, potencialmente, desplegarlo usando Vertex AI Endpoints para inferencia. Se complementaría con otros servicios GCP según necesidad (BigQuery para datos, Cloud Storage para artefactos, etc.). Esta opción representa la ruta "enterprise" con todos los servicios de ML totalmente gestionados, aunque puede ser excesiva dada la escala de este proyecto.

·  	**Componentes**:

·  	**Vertex AI Training**: Se puede aprovechar Vertex AI para entrenar/re-entrenar el modelo en la nube. Por ejemplo, usar **Vertex AI Notebooks** o un **Custom Job** para correr el código de entrenamiento (p. ej. un script Python que lee datos de BigQuery/Cloud Storage, entrena un modelo sklearn/TF, y guarda el modelo). Dado que la data es pequeña, se podría usar una máquina pequeña (n1-standard-4) por quizás minutos; el costo sería bajo (Vertex AI cobra por nodo/hora de entrenamiento, una VM estándar podría costar \~$0.10/hora, por lo que entrenar unos minutos costaría centavos). Además, **Vertex AI Pipeline** podría orquestar todo (ingesta de datos \-\> entrenamiento \-\> registro).

·  	**Vertex Model Registry**: Tras entrenar, el modelo resultante (artifacts) se puede guardar en Vertex AI Model Registry, lo que facilita su despliegue posterior y versionamiento.

·  	**Vertex AI Endpoint (Online Prediction)**: Para servir predicciones en tiempo real, Vertex permite desplegar el modelo en un endpoint HTTPS administrado. Esto manejaría el scaling e inferencia sin que el desarrollador tenga que crear la API manualmente. Sin embargo, hay una **consideración crítica de costo**: un endpoint de Vertex reserva máquinas *siempre activas*. Incluso el más básico (CPU) cuesta *\~$0.75 USD por hora por nodo*[\[11\]](https://www.reddit.com/r/googlecloud/comments/1jfk2jb/confused_about_pricing_differences_between_vertex/#:~:text=But%20here%27s%20where%20I%27m%20confused%3A), lo que implica **\>$500 USD/mes** si está 24/7, excediendo enormemente el presupuesto permitido. Vertex Endpoints **no escalan a cero** cuando no hay tráfico[\[12\]](https://engineering.doit.com/vertex-ai-cloudrun-96148eee7ce0?gi=43b757babb23#:~:text=At%20DoiT%2C%20we%20noticed%20that,In%20a%20nutshell%3A%20Zero%20Scaling)[\[13\]](https://engineering.doit.com/vertex-ai-cloudrun-96148eee7ce0?gi=43b757babb23#:~:text=,handle%20prediction%20or%20explanation%20requests), por lo que incurren en costos aunque no se use (son VMs dedicadas). Esto hace que **no sea viable** mantener un endpoint Vertex online permanentemente con solo $5 al mes.

`o`   *Posible solución*: Usar Vertex Endpoint **solo cuando se necesite**. Por ejemplo, desplegar el endpoint en los momentos de inferencia y apagarlo después. De hecho, se puede programar con Cloud Scheduler jobs que **desplieguen y deshabiliten** el modelo en Vertex según horario[\[14\]](https://engineering.doit.com/vertex-ai-cloudrun-96148eee7ce0?gi=43b757babb23#:~:text=To%20address%20this%20issue%2C%20we%E2%80%99ll,the%20Cloud%20Run%20jobs)[\[15\]](https://engineering.doit.com/vertex-ai-cloudrun-96148eee7ce0?gi=43b757babb23#:~:text=1,Create%20jobs%20scheduling). En nuestro caso, como la evaluación son 5 días consecutivos, se podría automatizar que el endpoint esté activo solo durante ciertas horas esos días. Aún así, la gestión es compleja y arriesgada (podría fallar un redeploy) y roza los límites de la prueba técnica.

`o`   *Alternativa híbrida*: Usar Vertex solo para entrenamiento y batch prediction. En vez de un endpoint online, se puede realizar **predicciones batch** con Vertex (Job que lee datos y genera predicciones en archivo) y luego servir esas predicciones con una solución como Cloud Run o Cloud Functions. Esto aprovecha Vertex para el ML pesado pero evita su costo en producción continua.

·  	**BigQuery/Storage**: Vertex integra bien con BigQuery (se puede entrenar AutoML Tables o BigQuery ML desde Vertex), y con **Cloud Storage** (para almacenar datasets y resultados). Por ejemplo, los datos históricos pueden residir en BQ, y el script de entrenamiento los consulta. El modelo entrenado puede guardarse en GCS o Model Registry. Las predicciones batch podrían escribirse a GCS en formato CSV/JSON.

* **Endpoint API (alternativo)**: Si no se usa Vertex Endpoint por costo, igualmente necesitamos un endpoint HTTP. Se volvería a las soluciones de Cloud Run o Functions para exponer el resultado. Por ejemplo, un Cloud Run muy ligero que simplemente lea la predicción precalculada que Vertex produjo. Dado que Vertex puede programarse para generar una predicción diaria, esa se almacena en GCS, y el Cloud Run la sirve. Esto combina Vertex (para ML) con Cloud Run (para API), intentando lo mejor de ambos.  
* **Ventajas**:  
  ·  	**Facilidad de entrenamiento y escalamiento de ML**: Vertex AI ofrece un entorno poderoso para el desarrollo de modelos. Si en un futuro se necesita probar modelos más complejos (p. ej. modelos de deep learning, incluir muchísimas variables), Vertex facilita usar GPUs, TPUs, AutoML, hyperparameter tuning, etc., todo administrado. Para el candidato, demostrar manejo de Vertex AI podría ser bien visto, ya que es la plataforma unificada de Google para IA[\[8\]](https://niveussolutions.com/google-cloud-ai-models-deployment/#:~:text=Relevant%20Google%20Cloud%20Services%20for,Model%20Deployment).  
  ·  	**Integración de pipeline**: Con Vertex Pipelines se puede orquestar todo el flujo (desde obtención de datos hasta despliegue) de forma reproducible. Esto favorece buenas prácticas MLOps, aunque tal vez sea overkill para una demo.  
  ·  	**Vertex AI Endpoints (si se usaran)** proporcionan *auto-escalado*, monitoreo integrado, y **SLA de enterprise**. Son apropiados si se necesitara alta disponibilidad y confiabilidad a nivel empresarial[\[16\]](https://www.reddit.com/r/googlecloud/comments/1jfk2jb/confused_about_pricing_differences_between_vertex/#:~:text=%E2%80%A2%20%206mo%20ago). En este caso de prueba, probablemente no se exija tal nivel, pero es bueno mencionarlo.  
  ·  	**BigQuery integración**: Vertex AI puede entrenar modelos AutoML directamente desde BigQuery sin mover datos. Por ejemplo, se podría haber usado AutoML Forecasting (si existiera para series temporales) o AutoML Tables con los datos, todo dentro de Vertex. Esto minimiza la manipulación manual de datos.  
* **Retraining en la nube**: Dado que eventualmente se quiere re-entrenar en GCP, Vertex es el lugar natural para programar re-entrenamientos (se puede usar Cloud Scheduler para lanzar un Custom Job de Vertex cada mes que re-entrene con los nuevos datos). Estos jobs solo consumen recursos mientras corren, así que el costo mensual podría mantenerse bajo si solo entrenamos esporádicamente.  
* **Desafíos**:  
  ·  	**Costo de despliegue en Vertex**: Como se explicó, mantener un endpoint de Vertex encendido rompe el presupuesto. Aunque sea técnicamente una opción, habría que argumentar claramente que **no es viable con $5/mes**, y optar por soluciones híbridas (por ejemplo, Vertex \+ Cloud Run en lugar de Vertex endpoint). De hecho, documentación y usuarios confirman que Vertex Endpoint siempre tiene al menos un nodo consumiendo horas, sin opción de escala a cero[\[17\]](https://datatonic.com/insights/deploying-machine-learning-models-google-cloud/#:~:text=and%20poses%20no%20restrictions%20on,container%20images)[\[18\]](https://datatonic.com/insights/deploying-machine-learning-models-google-cloud/#:~:text=Another%20benefit%20of%20using%20Cloud,the%20endpoint%20receives%20no%20requests).  
  ·  	**Complejidad de implementación**: *Alta*. Vertex AI tiene una curva de aprendizaje. Para desplegar un modelo custom hay que containerizarlo o cumplir ciertas especificaciones de empaquetado. Configurar un Pipeline CI/CD en Vertex en una semana puede ser mucho. Incluso usar Vertex Batch Prediction implica preparar el dataset de predicción y manejar los outputs. Comparado con un simple Cloud Run/Function, aquí hay más pasos, más YAML/JSON de configuración, y uso de gcloud o SDK. Es fácil perder tiempo en detalles de configuración de IAM, permisos, etc., que en un proyecto pequeño quizás no aportan valor a la solución final.  
  ·  	**Aprovisionamiento de API Key y rate limit**: Si usáramos Vertex Endpoint directamente, habría que protegerlo. Vertex Endpoints podrían requerir OAuth o una API Gateway al frente para implementar el API Key. Nuevamente estaríamos trayendo API Gateway, con la complejidad asociada (aunque es similar a las otras opciones). Si en cambio usamos Cloud Run como front-end, volvemos a la lógica de auth en la app.  
* **Sobre-solución**: Existe el riesgo de que esta arquitectura se perciba como usar “un cañón para matar una mosca”. Para un problema de una sola serie temporal y un endpoint sencillo, montar todo Vertex AI podría considerarse exagerado, especialmente si el jurado busca pragmatismo. A menos que esperen explícitamente que se use Vertex, podría ser mejor mencionarlo pero aclarar por qué se optaría por alternativas más simples en este caso.  
* **Dificultad estimada**: **Alta** para desplegar completamente con Vertex Endpoints dentro de los límites. **Media** si se limita su uso solo a entrenamiento. El candidato tendría que invertir bastante tiempo en configurar y probar Vertex (que puede consumir buena parte de los 7 días de la prueba). Implementar un pipeline completo y además el endpoint quizá no sea realista en ese plazo con el presupuesto dado. No obstante, *presentar esta opción muestra conocimiento de la plataforma*. Se puede proponer, por ejemplo: *“Entrenar el modelo con Vertex AI y exportar la predicción para que un Cloud Run la sirva”*, como un compromiso que usa Vertex donde aporta valor (entrenamiento gestionado) pero evita su punto débil (coste de endpoint 24/7).

En resumen, **Vertex AI** es la opción más robusta a largo plazo para integrar el ciclo de vida de ML en GCP, pero para la entrega puntual con fuerte restricción de costo, probablemente **no sea la opción principal de despliegue del endpoint**. Una solución híbrida (Vertex para ML offline \+ Cloud Run/Functions para servir) tendría mérito, pero agregar Vertex para este caso singular puede aumentar la dificultad sin un beneficio proporcional en la demo de 5 días.

## Comparación de Opciones y Recomendación

**Todas las opciones anteriores son viables técnicamente** para cumplir con el objetivo de servir una predicción de precio diariamente, pero difieren en complejidad y adecuación al presupuesto:

·  	**Costos**: Las **Opciones 1 y 2** se ajustan cómodamente al límite de $5/mes aprovechando recursos siempre gratuitos de GCP (Cloud Run/Functions, BigQuery)[\[3\]](https://www.reddit.com/r/googlecloud/comments/ow15n0/cloud_run_free_tier/#:~:text=The%20free%20tier%20specifically%20is%3A)[\[9\]](https://www.getgalaxy.io/learn/glossary/is-bigquery-free#:~:text=Is%20BigQuery%20free%3F). La **Opción 3** (Vertex) podría incurrir en costos significativos si se usa un endpoint siempre activo (no recomendable)[\[18\]](https://datatonic.com/insights/deploying-machine-learning-models-google-cloud/#:~:text=Another%20benefit%20of%20using%20Cloud,the%20endpoint%20receives%20no%20requests). Usándola solo para entrenamiento es manejable en costo, pero el endpoint igualmente tendría que ser Cloud Run/Functions, volviendo al patrón de las opciones 1-2.

·  	**Facilidad de implementación**: La **Opción 2 (Cloud Functions \+ BQ)** quizás sea la más rápida de implementar si el modelo puede ser simple (ej. ARIMA en BQ ML) y el desarrollador es ágil en SQL. Requiere menos configuración de infraestructura. La **Opción 1 (Cloud Run)** demanda conocimientos de Docker y backend web, pero ofrece máxima flexibilidad; su dificultad es moderada pero factible dentro de la prueba. La **Opción 3 (Vertex)** conlleva la mayor complejidad; probablemente no sea necesaria a menos que se busque impresionar mostrando manejo de Vertex, pero hay riesgo de no alcanzar a pulir todos los detalles en una semana.

·  	**Rendimiento y escalabilidad**: Las tres opciones pueden lograr respuesta \<2s si se precalcula la predicción. Cloud Run/Functions tienen tiempos de arranque y latencia mínimos con carga baja. Vertex Endpoint tendría buen rendimiento pero su escalabilidad a costos bajos es el problema. Para 60 req/min, cualquiera de las opciones 1 o 2 maneja ese tráfico sin pestañear.

·  	**Mantenimiento futuro**: Si se piensa en futuro (más datos, más modelos), la arquitectura Cloud Run/Functions es fácil de extender (se puede aumentar lógica de features, etc., dentro del código). BigQuery ML escalaria si los datos crecen, pero tiene límites en tipos de modelo. Vertex escalaria en cuanto a pipelines, pero quizás sea un exceso para un solo modelo. Dado que los re-entrenamientos serán poco frecuentes (mensuales), una solución ligera con unos cuantos scripts (en lugar de un pipeline complejo) podría ser suficiente.

**Recomendación**: Una **arquitectura híbrida combinando lo mejor de Opción 1 y 2** sería recomendable. Por ejemplo: **usar Cloud Run para el endpoint** (por flexibilidad en personalizar auth, formato de respuesta, etc.) y **BigQuery/Cloud Storage para almacenar datos y predicciones precalculadas**. Se puede entrenar el modelo localmente o con BigQuery ML inicialmente, y luego programar actualizaciones mensuales del modelo ya sea re-ejecutando la training en BigQuery ML o subiendo nuevos parámetros a Cloud Storage. Esta combinación garantiza costo casi nulo, simplicidad y cumplimiento de todos los requerimientos.

En términos de dificultad, implementar Cloud Run \+ BigQuery es manejable dentro del tiempo dado. Se puede incluso simplificar: dado que los datos son mensuales y de poca volatilidad diaria, una estrategia podría ser predecir que *“el precio de mañana será igual al de hoy”* (modelo naive) como baseline; eso se puede calcular sin modelo complejo y almacenarlo. Luego, con más tiempo, se podría mejorar el modelo incorporando estacionalidad o indicadores.

Por último, es importante **justificar brevemente la elección en la documentación**: por qué se usó esa arquitectura y cómo cumple el presupuesto y requisitos. Citando lineamientos: *“La solución debe operar con \<$5/mes”*\[19\] – nuestras opciones 1/2 demuestran esto con uso de free tier. También mencionar cómo se maneja la autenticación y cache de predicciones (por ejemplo, “predicción precalculada cada 24h, almacenada para servir en \<100ms, evitando recálculo por hora” – alineado a evitar recálculos innecesarios\[2\]). Con estas consideraciones, la arquitectura propuesta será sólida y defendible ante evaluadores, mostrando un buen equilibrio entre **innovación y pragmatismo** en el uso de tecnologías de Google Cloud.

---

\[1\] \[2\] \[7\] \[19\] caso\_cdo\_deacero\_contenido.txt

file://file\_00000000a56c6246876162bc0ebc4824

[\[3\]](https://www.reddit.com/r/googlecloud/comments/ow15n0/cloud_run_free_tier/#:~:text=The%20free%20tier%20specifically%20is%3A) Cloud Run Free Tier : r/googlecloud

[https://www.reddit.com/r/googlecloud/comments/ow15n0/cloud\_run\_free\_tier/](https://www.reddit.com/r/googlecloud/comments/ow15n0/cloud_run_free_tier/)

[\[4\]](https://cloudchipr.com/blog/google-cloud-functions#:~:text=Free%20tier%20recap%20,central1%20example) [\[10\]](https://cloudchipr.com/blog/google-cloud-functions#:~:text=There%E2%80%99s%20also%20a%20free%20tier%3A,are%20billed%20separately) Google Cloud Functions in 2025: What Teams Should Know

[https://cloudchipr.com/blog/google-cloud-functions](https://cloudchipr.com/blog/google-cloud-functions)

[\[5\]](https://datatonic.com/insights/deploying-machine-learning-models-google-cloud/#:~:text=Deploying%20models%20with%20Google%20Cloud,no%20restrictions%20on%20container%20images) [\[6\] \[17\]](https://datatonic.com/insights/deploying-machine-learning-models-google-cloud/#:~:text=and%20poses%20no%20restrictions%20on,container%20images) [\[18\]](https://datatonic.com/insights/deploying-machine-learning-models-google-cloud/#:~:text=Another%20benefit%20of%20using%20Cloud,the%20endpoint%20receives%20no%20requests) Deploying Machine Learning Models on Google Cloud | Datatonic

[https://datatonic.com/insights/deploying-machine-learning-models-google-cloud/](https://datatonic.com/insights/deploying-machine-learning-models-google-cloud/)

[\[8\]](https://niveussolutions.com/google-cloud-ai-models-deployment/#:~:text=Relevant%20Google%20Cloud%20Services%20for,Model%20Deployment) Google Cloud AI Deployment: For efficient AI Solutions

[https://niveussolutions.com/google-cloud-ai-models-deployment/](https://niveussolutions.com/google-cloud-ai-models-deployment/)

[\[9\]](https://www.getgalaxy.io/learn/glossary/is-bigquery-free#:~:text=Is%20BigQuery%20free%3F) Is Google BigQuery Free? Free Tier Explained | Galaxy

[https://www.getgalaxy.io/learn/glossary/is-bigquery-free](https://www.getgalaxy.io/learn/glossary/is-bigquery-free)

[\[11\]](https://www.reddit.com/r/googlecloud/comments/1jfk2jb/confused_about_pricing_differences_between_vertex/#:~:text=But%20here%27s%20where%20I%27m%20confused%3A) [\[16\]](https://www.reddit.com/r/googlecloud/comments/1jfk2jb/confused_about_pricing_differences_between_vertex/#:~:text=%E2%80%A2%20%206mo%20ago) Confused about pricing differences between Vertex AI and Google AI Studio \- especially deployment costs : r/googlecloud

[https://www.reddit.com/r/googlecloud/comments/1jfk2jb/confused\_about\_pricing\_differences\_between\_vertex/](https://www.reddit.com/r/googlecloud/comments/1jfk2jb/confused_about_pricing_differences_between_vertex/)

[\[12\]](https://engineering.doit.com/vertex-ai-cloudrun-96148eee7ce0?gi=43b757babb23#:~:text=At%20DoiT%2C%20we%20noticed%20that,In%20a%20nutshell%3A%20Zero%20Scaling) [\[13\]](https://engineering.doit.com/vertex-ai-cloudrun-96148eee7ce0?gi=43b757babb23#:~:text=,handle%20prediction%20or%20explanation%20requests) [\[14\]](https://engineering.doit.com/vertex-ai-cloudrun-96148eee7ce0?gi=43b757babb23#:~:text=To%20address%20this%20issue%2C%20we%E2%80%99ll,the%20Cloud%20Run%20jobs) [\[15\]](https://engineering.doit.com/vertex-ai-cloudrun-96148eee7ce0?gi=43b757babb23#:~:text=1,Create%20jobs%20scheduling) Vertex AI Prediction cost reduction, through the use of Cloud Run Jobs | by Nadav Weissman | DoiT

[https://engineering.doit.com/vertex-ai-cloudrun-96148eee7ce0?gi=43b757babb23](https://engineering.doit.com/vertex-ai-cloudrun-96148eee7ce0?gi=43b757babb23)
