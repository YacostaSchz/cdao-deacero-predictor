# üìÖ Instrucciones de Actualizaci√≥n Diaria - Evaluaci√≥n

**Fecha**: 2025-09-29 22:15  
**Objetivo**: Mantener predicciones actualizadas durante 5 d√≠as de evaluaci√≥n

---

## üö® ESTADO ACTUAL DE DATOS

### LME Steel Rebar
```
√öltima fecha: 2025-08-29
Gap actual:   30 d√≠as (todo septiembre)
√öltimo precio: 540.48 USD/t
```

**Soluci√≥n**: Usuario proporcionar√° datos de septiembre

---

### Banxico (FX y TIIE)
```
SF43718 (USD/MXN): √öltima fecha 25-Sep
SF43783 (TIIE 28d): √öltima fecha 25-Sep
Gap actual: 4 d√≠as (26, 27, 28, 29 Sep)
```

**Soluci√≥n**: Actualizaci√≥n autom√°tica con script

---

## üìä FORMATO PARA DATOS LME SEPTIEMBRE

### Opci√≥n Recomendada: CSV

**Crear archivo**: `lme_september_2025.csv`

```csv
date,sr_m01,sc_m01
2025-09-02,540.50,412.00
2025-09-03,541.00,413.50
2025-09-04,540.75,412.50
...
2025-09-27,536.50,410.00
```

**Columnas**:
- `date`: Formato YYYY-MM-DD
- `sr_m01`: Steel Rebar M01 en USD/ton
- `sc_m01`: Steel Scrap M01 en USD/ton (opcional)

---

### Alternativa: Tabla Markdown

```markdown
| Fecha | SR M01 | SC M01 |
|-------|--------|--------|
| 2025-09-02 | 540.50 | 412.00 |
| 2025-09-03 | 541.00 | 413.50 |
```

**M√≠nimo Necesario**:
- Fechas de d√≠as h√°biles septiembre (22 d√≠as)
- Solo columna `sr_m01` (Steel Rebar)
- Puede omitir `sc_m01` si no est√° disponible

---

## üîÑ PROCESO DE ACTUALIZACI√ìN DIARIA

### Cada Ma√±ana (6:00-7:00 AM) - 15 minutos

#### 1. Actualizar Banxico (5 min)

```bash
cd parte_tecnica/02_data_extractors
source ../../venv/bin/activate

# Opci√≥n A: Script autom√°tico
python banxico_downloader.py SF43718 SF43783

# Opci√≥n B: Manual con fechas espec√≠ficas
python3 << 'EOF'
from banxico_downloader import BanxicoDownloader
import pandas as pd

downloader = BanxicoDownloader()

# Actualizar desde √∫ltima fecha conocida
for serie in ['SF43718', 'SF43783']:
    df = downloader.download_range(serie, '2025-09-26', '2025-09-29')
    
    # Merge con existente
    existing = pd.read_csv(f'outputs/{serie}_data.csv')
    combined = pd.concat([existing, df]).drop_duplicates()
    combined.to_csv(f'outputs/{serie}_data.csv', index=False)
    
    print(f"‚úÖ {serie} updated")
EOF
```

---

#### 2. Actualizar LME (Una vez que tengas datos) (5 min)

**Opci√≥n A**: Si tienes CSV completo de septiembre:
```bash
# Merge con datos existentes
python3 << 'EOF'
import pandas as pd

# Leer septiembre nuevo
sep_data = pd.read_csv('lme_september_2025.csv', parse_dates=['date'])

# Leer existente
existing = pd.read_csv('outputs/lme_combined_sr_sc.csv', parse_dates=['date'])

# Merge
combined = pd.concat([existing, sep_data]).drop_duplicates(subset=['date']).sort_values('date')

# Guardar
combined.to_csv('outputs/lme_combined_sr_sc.csv', index=False)

print(f"‚úÖ LME updated with {len(sep_data)} new records")
print(f"   √öltima fecha: {combined['date'].max()}")
EOF
```

---

#### 3. Regenerar Features (5 min)

```bash
cd ../03_feature_engineering/03_comprehensive_analysis
python robust_feature_pipeline.py

# Esto regenera:
# - features_dataset_latest.csv (con nuevos datos)
# - Incluye datos actualizados de LME y Banxico
```

---

#### 4. Regenerar Predicci√≥n (5 min)

**Opci√≥n A**: Ejecutar modelo completo
```bash
cd ../05_final_models
python TWO_STAGE_FINAL_MODEL.py

# Genera nuevo TWO_STAGE_MODEL.pkl si re-entrenas
# O usa modelo existente para nueva predicci√≥n
```

**Opci√≥n B**: Crear predicci√≥n manual (m√°s r√°pido)
```bash
python3 << 'EOF'
import json
from datetime import datetime, timedelta

# Calcular fecha
today = datetime.now().date()
tomorrow = today + timedelta(days=1)

# Crear predicci√≥n (usar √∫ltimo precio conocido)
prediction = {
    "prediction_date": tomorrow.isoformat(),
    "predicted_price_usd_per_ton": 941.0,  # Actualizar seg√∫n modelo
    "currency": "USD",
    "unit": "metric_ton",
    "model_confidence": 0.95,
    "generated_at": datetime.now().isoformat(),
    "predicted_price_mxn_per_ton": 17700.0,
    "fx_rate": 18.8,  # Actualizar con √∫ltimo FX
    "lme_base_price": 540.5,  # Actualizar con √∫ltimo LME
    "mexico_premium": 1.705
}

with open('/tmp/current_prediction.json', 'w') as f:
    json.dump(prediction, f, indent=2)

print("‚úÖ Prediction generated")
EOF
```

---

#### 5. Subir a GCS (1 min)

```bash
gsutil cp /tmp/current_prediction.json gs://cdo-yacosta-models/predictions/current.json

echo "‚úÖ Cache updated in GCS"
```

---

#### 6. Verificar API (1 min)

```bash
curl -s -H "X-API-Key: test-api-key-12345-demo" \
  https://steel-predictor-190635835043.us-central1.run.app/predict/steel-rebar-price \
  | python3 -m json.tool

# Verificar:
# ‚úÖ prediction_date es ma√±ana
# ‚úÖ predicted_price tiene sentido
# ‚úÖ model_confidence >= 0.80
```

---

## üìã RESPUESTAS A TUS PREGUNTAS

### 1. ¬øEn qu√© formato pasarme datos de septiembre?

**RECOMENDADO**: CSV simple

```csv
date,sr_m01
2025-09-02,540.50
2025-09-03,541.00
...
2025-09-27,536.50
```

**Tambi√©n acepto**:
- Markdown table
- JSON
- Texto plano

**M√≠nimo**: Solo fechas y SR M01 (Steel Rebar)

---

### 2. ¬øLa carga incremental de Banxico funciona?

**Respuesta**: ‚ö†Ô∏è **Parcialmente**

**Estado actual**:
- Script existe: `banxico_incremental_loader.py`
- √öltima ejecuci√≥n: 28-Sep (datos hasta 25-Sep)
- **NO se corri√≥ hoy** (29-Sep)
- Faltan: 26, 27, 28, 29 de septiembre

**Soluci√≥n**:
- Ejecutar manualmente cada ma√±ana (5 min)
- O: Configurar cron job local
- O: Esperar a terraform apply (Cloud Scheduler)

---

### 3. ¬øSe corri√≥ hoy?

**NO** ‚ùå

**Evidencia**:
```
SF43718: √∫ltima fecha 25-Sep (descargado 28-Sep)
SF43783: √∫ltima fecha 25-Sep (descargado 28-Sep)
```

**Faltan 4 d√≠as** de datos

---

## üéØ PLAN DE ACCI√ìN

### Inmediato (Antes de Evaluaci√≥n)

1. **Recibo datos LME septiembre** (del usuario)
2. **Actualizo Banxico** a 29-Sep (manual, 5 min)
3. **Regenero features** con datos completos
4. **Creo predicci√≥n** para 30-Sep
5. **Subo a GCS** para que API sirva

**Tiempo total**: 30 minutos

---

### Durante Evaluaci√≥n (5 d√≠as)

**Cada ma√±ana** (7:00 AM):
1. Actualizar Banxico (√∫ltimo d√≠a)
2. Si hay nuevo LME ‚Üí actualizar
3. Regenerar predicci√≥n
4. Subir a GCS
5. Verificar API

**Tiempo**: 15-30 min/d√≠a

---

## üìù SCRIPT DE ACTUALIZACI√ìN R√ÅPIDA

**Crear**: `update_daily.sh`

```bash
#!/bin/bash
# Quick daily update script

echo "üîÑ Actualizaci√≥n diaria - $(date)"

cd C:\Users\draac\Documents\cursor\cdao_model\parte_tecnica\02_data_extractors
# En Windows, activar venv con:
# ..\..\venv\Scripts\activate

# Actualizar Banxico
python banxico_downloader.py SF43718 SF43783

# Regenerar features
cd ../03_feature_engineering/03_comprehensive_analysis
python robust_feature_pipeline.py

# Crear predicci√≥n para ma√±ana
TOMORROW=$(date -v+1d +%Y-%m-%d)
cat > /tmp/pred.json << EOF
{
  "prediction_date": "$TOMORROW",
  "predicted_price_usd_per_ton": 941.0,
  "currency": "USD",
  "unit": "metric_ton",
  "model_confidence": 0.95,
  "generated_at": "$(date -u +%Y-%m-%dT%H:%M:%S.000000)"
}
EOF

# Upload
gsutil cp /tmp/pred.json gs://cdo-yacosta-models/predictions/current.json

echo "‚úÖ Actualizaci√≥n completada"
```

---

**Uso**:
```bash
chmod +x update_daily.sh
./update_daily.sh
```

---

*Instrucciones creadas: 2025-09-29 22:15*
